{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAP1QHChVQZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile, os\n",
        "local_zip = '/content/dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kxAQEScVyw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "# Images Dimensions\n",
        "img_width, img_height = 128, 128\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 800\n",
        "nb_validation_samples = 240\n",
        "epochs = 50\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AudvaEZSV2Rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorBoard Callbacks\n",
        "callbacks = TensorBoard(log_dir='./Graph')\n",
        "\n",
        "# Build VGG16\n",
        "model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "\n",
        "# Training Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Rescale Testing Data\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "# Train Data Generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "train_features = model.predict_generator(\n",
        "    train_generator, nb_train_samples // batch_size, verbose=1)\n",
        "np.save('train_features.npy', train_features)\n",
        "\n",
        "# Testing Data Generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "validation_features = model.predict_generator(\n",
        "    validation_generator, nb_validation_samples // batch_size, verbose=1)\n",
        "np.save('val_features.npy', validation_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdDAR_izWJY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build Train Data\n",
        "train_data = np.load('/content/train_features.npy')\n",
        "train_labels = np.array(\n",
        "    [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "# Build Validation Data\n",
        "validation_data = np.load('/content/val_features.npy')\n",
        "validation_labels = np.array(\n",
        "    [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOb3uNr2WpLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build FC Layer\n",
        "fc_model = Sequential()\n",
        "fc_model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "fc_model.add(Dense(32, activation='relu'))\n",
        "fc_model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge7U6daGWtZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adam Optimizer and Cross Entropy Loss\n",
        "adam = Adam(lr=0.001)\n",
        "fc_model.compile(optimizer=adam,\n",
        "                loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "fc_model.fit(train_data, train_labels,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(validation_data, validation_labels), \n",
        "            callbacks=[callbacks])\n",
        "            \n",
        "fc_model.save_weights('vgg16.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4tBBsi1XET5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_width, img_height = 128, 128\n",
        "\n",
        "test_data_dir = '/content/testing'\n",
        "\n",
        "def get_features():\n",
        "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # build the VGG16 network\n",
        "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=1,\n",
        "        class_mode='binary',\n",
        "        shuffle=False)\n",
        "    features = model.predict_generator(\n",
        "        generator, 8)\n",
        "    return features\n",
        "\n",
        "def get_score():\n",
        "    features = get_features()    \n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=features.shape[1:]))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "        \n",
        "    model.load_weights('vgg16.py')\n",
        "\n",
        "    score = model.predict(features)\n",
        "    print(score)\n",
        "\n",
        "get_score()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhkC359Zm9zB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "img=mpimg.imread('/content/testing/face/2.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eALFC-8E6eQd",
        "colab_type": "text"
      },
      "source": [
        "PRE TRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QIVieif84TF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import densenet\n",
        "from keras.preprocessing import image\n",
        "from keras import applications\n",
        "from keras.applications.densenet import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import os\n",
        "\n",
        "# Images Dimensions\n",
        "img_width, img_height = 128, 128\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 800\n",
        "nb_validation_samples = 240\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "category_dict = train_generator.class_indices\n",
        "print(category_dict)\n",
        "\n",
        "number_of_classes = len(category_dict)\n",
        "\n",
        "model = applications.VGG16(include_top=False, weights='imagenet')\n",
        "x = model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "preds = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=model.input, outputs=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpJOl2yj6kqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(model.layers))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MTG8TtL4-Gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the first n_freeze layers of the network to be non-trainable.\n",
        "n_freeze = 3\n",
        "for layer in model.layers[:n_freeze]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[n_freeze:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_KcT0AIAMjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = Adam(lr=0.001)\n",
        "model.compile(optimizer=adam,\n",
        "                loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "step_size_train = train_generator.n//train_generator.batch_size\n",
        "model.fit_generator(generator=train_generator, \n",
        "                    steps_per_epoch=step_size_train, \n",
        "                    epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDwiOxlNBli0",
        "colab_type": "text"
      },
      "source": [
        "XCEPTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXvUotoxAV90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "# Images Dimensions\n",
        "img_width, img_height = 128, 128\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 800\n",
        "nb_validation_samples = 240\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "# TensorBoard Callbacks\n",
        "callbacks = TensorBoard(log_dir='./Graph')\n",
        "\n",
        "# Build VGG16\n",
        "model = applications.Xception(include_top=False, weights='imagenet')\n",
        "\n",
        "# Training Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Rescale Testing Data\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "# Train Data Generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "train_features = model.predict_generator(\n",
        "    train_generator, nb_train_samples // batch_size, verbose=1)\n",
        "np.save('train_features.npy', train_features)\n",
        "\n",
        "# Testing Data Generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "validation_features = model.predict_generator(\n",
        "    validation_generator, nb_validation_samples // batch_size, verbose=1)\n",
        "np.save('val_features.npy', validation_features)\n",
        "\n",
        "# Build Train Data\n",
        "train_data = np.load('/content/train_features.npy')\n",
        "train_labels = np.array(\n",
        "    [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
        "\n",
        "# Build Validation Data\n",
        "validation_data = np.load('/content/val_features.npy')\n",
        "validation_labels = np.array(\n",
        "    [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
        "\n",
        "# Build FC Layer\n",
        "fc_model = Sequential()\n",
        "fc_model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "fc_model.add(Dense(32, activation='relu'))\n",
        "fc_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Adam Optimizer and Cross Entropy Loss\n",
        "adam = Adam(lr=0.0001)\n",
        "fc_model.compile(optimizer=adam,\n",
        "                loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "fc_model.fit(train_data, train_labels,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(validation_data, validation_labels), \n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1fzq0BUCLe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}