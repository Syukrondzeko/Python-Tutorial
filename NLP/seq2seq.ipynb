{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Notebook Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 12:20:36.267296: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import unicodedata\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural Machine Translation Without Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # Normalize the input sentence to decompose accented characters into their base form\n",
    "    sent = \"\".join([c for c in unicodedata.normalize(\"NFD\", sent) if unicodedata.category(c) != \"Mn\"])\n",
    "    \n",
    "    # Add space before punctuation marks like '.', '!', or '?' to tokenize them separately\n",
    "    sent = re.sub(r\"([!.?])\", r\" \\1\", sent)\n",
    "    \n",
    "    # Replace any sequence of characters that are not letters or punctuation with a single space\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "    \n",
    "    # Replace multiple consecutive spaces with a single space\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    \n",
    "    # Convert the sentence to lowercase to ensure consistency in case\n",
    "    sent = sent.lower()\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(num_sent_pairs =20000):\n",
    "    en_sents, fr_sents_in, fr_sents_out = [], [], []\n",
    "    local_file = os.path.join(\"datasets\", \"fra.txt\")\n",
    "    with open(local_file, \"r\") as fin:\n",
    "        for i, line in enumerate(fin):\n",
    "            en_sent, fr_sent, _ = line.strip().split('\\t')\n",
    "            en_sent = [w for w in preprocess_sentence(en_sent).split()]\n",
    "            fr_sent = preprocess_sentence(fr_sent)\n",
    "            fr_sent_in = [w for w in (\"BOS \" + fr_sent).split()]\n",
    "            fr_sent_out = [w for w in (fr_sent + \" EOS\").split()]\n",
    "            en_sents.append(en_sent)\n",
    "            fr_sents_in.append(fr_sent_in)\n",
    "            fr_sents_out.append(fr_sent_out)\n",
    "            if i >= num_sent_pairs - 1:\n",
    "                break\n",
    "    return en_sents, fr_sents_in, fr_sents_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SENT_PAIRS = 1000\n",
    "sents_en, sents_fr_in, sents_fr_out = read_data(NUM_SENT_PAIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!'], ['run', '!']]\n"
     ]
    }
   ],
   "source": [
    "print(sents_en[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['BOS', 'va', '!'], ['BOS', 'salut', '!'], ['BOS', 'salut', '.'], ['BOS', 'cours', '!'], ['BOS', 'courez', '!']]\n"
     ]
    }
   ],
   "source": [
    "print(sents_fr_in[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['va', '!', 'EOS'], ['salut', '!', 'EOS'], ['salut', '.', 'EOS'], ['cours', '!', 'EOS'], ['courez', '!', 'EOS']]\n"
     ]
    }
   ],
   "source": [
    "print(sents_fr_out[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer_en: <keras.preprocessing.text.Tokenizer object at 0x7fdb50770130>\n",
      "data en: [[7, 1], [130, 1], [130, 1], [75, 3], [75, 3]]\n",
      "data en: \n",
      "[[  7   1   0   0   0]\n",
      " [130   1   0   0   0]\n",
      " [130   1   0   0   0]\n",
      " [ 75   3   0   0   0]\n",
      " [ 75   3   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# We declare the tokenizers and use them to transform texts to sequences of indices\n",
    "\n",
    "tokenizer_en = tf.keras.preprocessing.text.Tokenizer(filters=\"\", lower=False)\n",
    "print(f'tokenizer_en: {tokenizer_en}')\n",
    "tokenizer_en.fit_on_texts(sents_en)\n",
    "data_en = tokenizer_en.texts_to_sequences(sents_en)\n",
    "print(f'data en: {data_en[0:5]}')\n",
    "data_en = tf.keras.preprocessing.sequence.pad_sequences(data_en, padding=\"post\")\n",
    "print(f'data en: \\n{data_en[0:5]}')\n",
    "\n",
    "tokenizer_fr = tf.keras.preprocessing.text.Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_fr.fit_on_texts(sents_fr_in)\n",
    "tokenizer_fr.fit_on_texts(sents_fr_out)\n",
    "data_fr_in = tokenizer_fr.texts_to_sequences(sents_fr_in)\n",
    "data_fr_in = tf.keras.preprocessing.sequence.pad_sequences(data_fr_in, padding=\"post\")\n",
    "data_fr_out = tokenizer_fr.texts_to_sequences(sents_fr_out)\n",
    "data_fr_out = tf.keras.preprocessing.sequence.pad_sequences(data_fr_out, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size (en): 380, vocab size (fr): 709\n",
      "seqlen (en): 5, (fr): 10\n",
      "\n",
      "word2idx_en: \n",
      "\n",
      "{'.': 1, 'i': 2, '!': 3, 'm': 4, 'it': 5, 's': 6, 'go': 7, 'tom': 8, '?': 9, 'me': 10, 'up': 11, 'you': 12, 'be': 13, 'll': 14, 'get': 15, 'this': 16, 'lost': 17, 'we': 18, 'come': 19, 'let': 20, 'back': 21, 'take': 22, 'stay': 23, 'down': 24, 'on': 25, 'won': 26, 'they': 27, 'ok': 28, 'saw': 29, 'here': 30, 'that': 31, 'away': 32, 'he': 33, 'is': 34, 'mine': 35, 'try': 36, 'calm': 37, 'us': 38, 'stop': 39, 'no': 40, 'nice': 41, 'how': 42, 'look': 43, 'see': 44, 'in': 45, 'out': 46, 'am': 47, 'a': 48, 'fun': 49, 'over': 50, 'who': 51, 'help': 52, 'got': 53, 'way': 54, 'fair': 55, 'keep': 56, 'still': 57, 'him': 58, 'she': 59, 'call': 60, 'hold': 61, 'off': 62, 'grab': 63, 'must': 64, 'ahead': 65, 'good': 66, 'job': 67, 'did': 68, 'use': 69, 'don': 70, 't': 71, 'lie': 72, 'excuse': 73, 'forget': 74, 'run': 75, 'left': 76, 'home': 77, 'hurry': 78, 'sure': 79, 'leave': 80, 'what': 81, 'sorry': 82, 'fell': 83, 'ask': 84, 'cool': 85, 'drive': 86, 'fat': 87, 'open': 88, 'shut': 89, 'wake': 90, 'lazy': 91, 'sit': 92, 'can': 93, 'ready': 94, 'hot': 95, 'was': 96, 'lucky': 97, 'naked': 98, 'loosen': 99, 'of': 100, 'course': 101, 'fire': 102, 'cheers': 103, 'now': 104, 'lied': 105, 'drop': 106, 'slow': 107, 'hang': 108, 'quit': 109, 'cried': 110, 'tried': 111, 'tell': 112, 'cold': 113, 'free': 114, 'late': 115, 'new': 116, 'taste': 117, 'trust': 118, 'watch': 119, 'feel': 120, 'head': 121, 'beg': 122, 'had': 123, 'going': 124, 'tough': 125, 'sign': 126, 'care': 127, 'thank': 128, 'swam': 129, 'hi': 130, 'wait': 131, 'hello': 132, 'oh': 133, 'hug': 134, 'really': 135, 'agree': 136, 'hit': 137, 'sad': 138, 'wet': 139, 'kiss': 140, 'so': 141, 'them': 142, 'man': 143, 'have': 144, 'fine': 145, 'okay': 146, 've': 147, 'works': 148, 'may': 149, 'came': 150, 'died': 151, 'terrific': 152, 'catch': 153, 'win': 154, 'follow': 155, 'cringed': 156, 'pack': 157, 'work': 158, 'alive': 159, 'drunk': 160, 'fussy': 161, 'dead': 162, 'ours': 163, 'time': 164, 'move': 165, 'pardon': 166, 'seriously': 167, 'again': 168, 'attack': 169, 'hop': 170, 'know': 171, 'paid': 172, 'thanks': 173, 'goodbye': 174, 'runs': 175, 'dozed': 176, 'fired': 177, 'froze': 178, 'stood': 179, 'swore': 180, 'waved': 181, 'ill': 182, 'join': 183, 'too': 184, 'show': 185, 'wash': 186, 'beats': 187, 'find': 188, 'fix': 189, 'failed': 190, 'phoned': 191, 'refuse': 192, 'rested': 193, 'stayed': 194, 'pay': 195, 'busy': 196, 'deaf': 197, 'done': 198, 'full': 199, 'game': 200, 'rich': 201, 'sick': 202, 'thin': 203, 'tidy': 204, 'ugly': 205, 'well': 206, 'his': 207, 'marry': 208, 'save': 209, 'say': 210, 'speak': 211, 'knew': 212, 'some': 213, 'warn': 214, 'for': 215, 'write': 216, 'after': 217, 'seated': 218, 'soon': 219, 'dogs': 220, 'bark': 221, 'die': 222, 'to': 223, 'bed': 224, 'luck': 225, 'east': 226, 'west': 227, 'give': 228, 'hurried': 229, 'love': 230, 'mean': 231, 'need': 232, 'relaxed': 233, 'said': 234, 'one': 235, 'tripped': 236, 'woke': 237, 'd': 238, 'talk': 239, 'alone': 240, 'angry': 241, 'armed': 242, 'clean': 243, 'crazy': 244, 'cured': 245, 'loyal': 246, 'yours': 247, 'far': 248, 'stinks': 249, 'worked': 250, 'hers': 251, 'please': 252, 'below': 253, 'seize': 254, 'step': 255, 'mad': 256, 'wow': 257, 'jump': 258, 'fled': 259, 'listen': 260, 'awesome': 261, 'kind': 262, 'beat': 263, 'smoke': 264, 'snore': 265, 'stink': 266, 'fit': 267, 'shy': 268, 'perfect': 269, 'skip': 270, 'long': 271, 'welcome': 272, 'all': 273, 'rise': 274, 'cheer': 275, 'cuff': 276, 'real': 277, 'tries': 278, 'guys': 279, 'cute': 280, 'deep': 281, 'rude': 282, 'cursed': 283, 'forgot': 284, 'helped': 285, 'jumped': 286, 'looked': 287, 'moaned': 288, 'nodded': 289, 'obeyed': 290, 'sighed': 291, 'talked': 292, 'bald': 293, 'fast': 294, 'glad': 295, 'safe': 296, 'tall': 297, 'weak': 298, 'helps': 299, 'hurts': 300, 'odd': 301, 'red': 302, 'stand': 303, 'lies': 304, 'went': 305, 'hard': 306, 're': 307, 'aim': 308, 'answer': 309, 'birds': 310, 'fly': 311, 'bless': 312, 'chill': 313, 'do': 314, 'cry': 315, 'fantastic': 316, 'inside': 317, 'hands': 318, 'old': 319, 'dj': 320, 'sexy': 321, 'awful': 322, 'weird': 323, 'ski': 324, 'exhaled': 325, 'gave': 326, 'hate': 327, 'hope': 328, 'inhaled': 329, 'like': 330, 'noticed': 331, 'prepaid': 332, 'promise': 333, 'retired': 334, 'shouted': 335, 'want': 336, 'will': 337, 'cook': 338, 'live': 339, 'obey': 340, 'pass': 341, 'sing': 342, 'swim': 343, 'walk': 344, 'cop': 345, 'awake': 346, 'blind': 347, 'broke': 348, 'dizzy': 349, 'dying': 350, 'early': 351, 'first': 352, 'lying': 353, 'quiet': 354, 'right': 355, 'sober': 356, 'stuck': 357, 'timid': 358, 'tired': 359, 'bad': 360, 'poured': 361, 'snowed': 362, 'tv': 363, 'dark': 364, 'easy': 365, 'food': 366, 'sand': 367, 'true': 368, 'eat': 369, 'shot': 370, 'read': 371, 'above': 372, 'walks': 373, 'then': 374, 'cooks': 375, 'dived': 376, 'knits': 377, 'knows': 378, 'rocks': 379, 'spoke': 380}\n"
     ]
    }
   ],
   "source": [
    "# We then build up dictionaries and vocabularies\n",
    "\n",
    "vocab_size_en = len(tokenizer_en.word_index)\n",
    "vocab_size_fr = len(tokenizer_fr.word_index)\n",
    "\n",
    "word2idx_en = tokenizer_en.word_index\n",
    "idx2word_en = {v:k for k, v in word2idx_en.items()}\n",
    "word2idx_fr = tokenizer_fr.word_index\n",
    "idx2word_fr = {v:k for k, v in word2idx_fr.items()}\n",
    "\n",
    "print(\"vocab size (en): {:d}, vocab size (fr): {:d}\".format(vocab_size_en, vocab_size_fr))\n",
    "maxlen_en = data_en.shape[1]\n",
    "maxlen_fr = data_fr_out.shape[1]\n",
    "print(\"seqlen (en): {:d}, (fr): {:d}\".format(maxlen_en, maxlen_fr))\n",
    "\n",
    "print(f'\\nword2idx_en: \\n\\n{word2idx_en}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(64, 5), dtype=tf.int32, name=None), TensorSpec(shape=(64, 10), dtype=tf.int32, name=None), TensorSpec(shape=(64, 10), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Convert to dataset format\n",
    "\n",
    "batch_size = 64\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data_en, data_fr_in, data_fr_out))\n",
    "dataset = dataset.shuffle(10000)\n",
    "test_size = NUM_SENT_PAIRS // 4\n",
    "test_dataset = dataset.take(test_size).batch(batch_size, drop_remainder=True)\n",
    "train_dataset = dataset.skip(test_size).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_timesteps, encoder_dim, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=num_timesteps)\n",
    "        self.rnn = tf.keras.layers.GRU(encoder_dim, return_sequences=False, return_state=True)\n",
    "    \n",
    "    def call(self, x, state):\n",
    "        x = self.embedding(x)\n",
    "        x, state = self.rnn(x, initial_state=state) # x is output, and state is hidden state\n",
    "        return x, state\n",
    "    \n",
    "    def init_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.encoder_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_timesteps, decoder_dim, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.decoder_dim = decoder_dim\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length= num_timesteps)\n",
    "        self.rnn = tf.keras.layers.GRU(decoder_dim, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, state):\n",
    "        x = self.embedding(x)\n",
    "        x, state = self.rnn(x, state)\n",
    "        x = self.dense(x) # only return logits\n",
    "        return x, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "encoder_dim, decoder_dim = 1024, 1024\n",
    "\n",
    "# vocab size + 1 for word that is not in the library usually called as out-of-vocabulary (OOV)\n",
    "encoder = Encoder(vocab_size_en+1, embedding_dim, maxlen_en, encoder_dim)\n",
    "decoder = Decoder(vocab_size_fr+1, embedding_dim, maxlen_fr, decoder_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 12:49:59.019898: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype int32 and shape [1000,10]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input : (64, 5)\n",
      "encoder output : (64, 1024) state: (64, 1024)\n",
      "decoder output (logits): (64, 10, 710) state: (64, 1024)\n",
      "decoder output (labels): (64, 10)\n"
     ]
    }
   ],
   "source": [
    "encoder_in, decoder_in, decoder_out = next(iter(train_dataset))\n",
    "\n",
    "encoder_state = encoder.init_state(batch_size)\n",
    "encoder_out, encoder_state = encoder(encoder_in, encoder_state)\n",
    "decoder_state = encoder_state\n",
    "decoder_pred, decoder_state = decoder(decoder_in, decoder_state)\n",
    "\n",
    "print(\"encoder input :\", encoder_in.shape)\n",
    "print(\"encoder output :\", encoder_out.shape, \"state:\", encoder_state.shape)\n",
    "print(\"decoder output (logits):\", decoder_pred.shape, \"state:\", decoder_state.shape)\n",
    "print(\"decoder output (labels):\", decoder_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(ytrue, ypred):\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    mask = tf.math.logical_not(tf.math.equal(ytrue, 0))\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    loss = scce(ytrue, ypred, sample_weight=mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(encoder_in, decoder_in, decoder_out, encoder_state):\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoder_out, encoder_state = encoder(encoder_in, encoder_state)\n",
    "        decoder_state = encoder_state\n",
    "        decoder_pred, decoder_state = decoder(decoder_in, decoder_state)\n",
    "        loss = loss_fn(decoder_out, decoder_pred)\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder, decoder, batch_size, sents_en, data_en, sents_fr_out, word2idx_fr, idx2word_fr):\n",
    "    random_id = np.random.choice(len(sents_en))\n",
    "    print(\"input : \", \" \".join(sents_en[random_id]))\n",
    "    print(\"label : \", \" \".join(sents_fr_out[random_id]))\n",
    "    encoder_in = tf.expand_dims(data_en[random_id], axis=0)\n",
    "    decoder_out = tf.expand_dims(sents_fr_out[random_id], axis=0)\n",
    "    \n",
    "    encoder_state = encoder.init_state(1)\n",
    "    encoder_out, encoder_state = encoder(encoder_in, encoder_state)\n",
    "    \n",
    "    decoder_state = encoder_state\n",
    "    decoder_in = tf.expand_dims(tf.constant([word2idx_fr[\"BOS\"]]), axis=0)\n",
    "    \n",
    "    pred_sent_fr = []\n",
    "    decoding_step = 0\n",
    "    while decoding_step < maxlen_fr:\n",
    "        decoder_pred, decoder_state = decoder(decoder_in, decoder_state)\n",
    "        decoder_pred = tf.argmax(decoder_pred, axis=-1)\n",
    "        pred_word = idx2word_fr[decoder_pred.numpy()[0][0]]\n",
    "        pred_sent_fr.append(pred_word)\n",
    "        if pred_word == \"EOS\":\n",
    "            break\n",
    "        decoder_in = decoder_pred\n",
    "        decoding_step += 1\n",
    "    print(\"predicted: \", \" \".join(pred_sent_fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 12:57:17.221632: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-22 12:57:17.223254: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-22 12:57:17.224492: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-22 12:57:17.426208: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-22 12:57:17.427861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-22 12:57:17.429081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-22 12:57:18.356612: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-22 12:57:18.359148: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-22 12:57:18.361410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-22 12:57:18.560792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-22 12:57:18.562662: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-22 12:57:18.564135: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 2.1057\n",
      "input :  birds fly .\n",
      "label :  les oiseaux volent . EOS\n",
      "predicted:  je ! ! ! ! ! ! ! ! !\n",
      "Epoch: 2, Loss: 2.0041\n",
      "input :  i m free .\n",
      "label :  je suis libre . EOS\n",
      "predicted:  je . EOS\n",
      "Epoch: 3, Loss: 1.8604\n",
      "input :  i m sick .\n",
      "label :  je suis malade . EOS\n",
      "predicted:  je suis . EOS\n",
      "Epoch: 4, Loss: 1.5524\n",
      "input :  i looked .\n",
      "label :  j ai regarde . EOS\n",
      "predicted:  je suis . EOS\n",
      "Epoch: 5, Loss: 1.4870\n",
      "input :  tom spoke .\n",
      "label :  tom a parle . EOS\n",
      "predicted:  je suis . EOS\n",
      "Epoch: 6, Loss: 1.4353\n",
      "input :  call me .\n",
      "label :  appelez moi ! EOS\n",
      "predicted:  c est . EOS\n",
      "Epoch: 7, Loss: 1.2998\n",
      "input :  i m early .\n",
      "label :  je suis en avance . EOS\n",
      "predicted:  je suis suis . EOS\n",
      "Epoch: 8, Loss: 1.2780\n",
      "input :  go on .\n",
      "label :  poursuivez . EOS\n",
      "predicted:  nous ! EOS\n",
      "Epoch: 9, Loss: 1.0698\n",
      "input :  he s lazy .\n",
      "label :  il est paresseux . EOS\n",
      "predicted:  c est . EOS\n",
      "Epoch: 10, Loss: 1.1802\n",
      "input :  come on .\n",
      "label :  allez ! EOS\n",
      "predicted:  venez ! EOS\n",
      "Epoch: 11, Loss: 1.1607\n",
      "input :  go away .\n",
      "label :  degage ! EOS\n",
      "predicted:  nous a gagne . EOS\n",
      "Epoch: 12, Loss: 1.0738\n",
      "input :  forget it .\n",
      "label :  oublie . EOS\n",
      "predicted:  soyez calmes ! EOS\n",
      "Epoch: 13, Loss: 0.9771\n",
      "input :  tell me .\n",
      "label :  dites moi ! EOS\n",
      "predicted:  c est ici . EOS\n",
      "Epoch: 14, Loss: 0.9280\n",
      "input :  i m dizzy .\n",
      "label :  j ai la tete qui tourne . EOS\n",
      "predicted:  je suis dure . EOS\n",
      "Epoch: 15, Loss: 0.8490\n",
      "input :  beat it .\n",
      "label :  degage ! EOS\n",
      "predicted:  venez ! EOS\n",
      "Epoch: 16, Loss: 0.8953\n",
      "input :  get tom .\n",
      "label :  va chercher tom . EOS\n",
      "predicted:  restez a l . EOS\n",
      "Epoch: 17, Loss: 0.7975\n",
      "input :  i had fun .\n",
      "label :  je me suis marre . EOS\n",
      "predicted:  je suis en vie . EOS\n",
      "Epoch: 18, Loss: 0.7597\n",
      "input :  i fled .\n",
      "label :  j ai fui . EOS\n",
      "predicted:  j ai fait signe de la tete . EOS\n",
      "Epoch: 19, Loss: 0.6734\n",
      "input :  we won .\n",
      "label :  nous avons gagne . EOS\n",
      "predicted:  nous avons ete battues . EOS\n",
      "Epoch: 20, Loss: 0.5968\n",
      "input :  don t die .\n",
      "label :  ne meurs pas ! EOS\n",
      "predicted:  ne mourez pas ! EOS\n",
      "Epoch: 21, Loss: 0.6592\n",
      "input :  take care !\n",
      "label :  prends soin de toi ! EOS\n",
      "predicted:  prends soin de toi . EOS\n",
      "Epoch: 22, Loss: 0.5553\n",
      "input :  we lost .\n",
      "label :  nous perdimes . EOS\n",
      "predicted:  nous avons ete battues . EOS\n",
      "Epoch: 23, Loss: 0.5165\n",
      "input :  drop it !\n",
      "label :  laisse le tomber ! EOS\n",
      "predicted:  laisse tomber ! EOS\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = \"./checkpoints\"\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)\n",
    "num_epochs = 25\n",
    "eval_scores = []\n",
    "for e in range(num_epochs):\n",
    "    encoder_state = encoder.init_state(batch_size)\n",
    "    for batch, data in enumerate(train_dataset):\n",
    "        encoder_in, decoder_in, decoder_out = data\n",
    "        # print(encoder_in.shape, decoder_in.shape, decoder_out.shape)\n",
    "        loss = train_step(encoder_in, decoder_in, decoder_out, encoder_state)\n",
    "        # print(\"Batch {}: loss = {}\".format(batch, loss))\n",
    "    print(\"Epoch: {}, Loss: {:.4f}\".format(e + 1, loss.numpy()))\n",
    "    if e % 10 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    predict(encoder, decoder, batch_size, sents_en, data_en, sents_fr_out, word2idx_fr, idx2word_fr)\n",
    "\n",
    "checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
